{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Case Study analysis\n",
    "In this notebook we will produce all the necessary visualizations that are might be useful for the paper.\n",
    "From these visualizaitons a subset will be used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pyvis.network as network\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import graphviz\n",
    "import tabulate as tabulate\n",
    "from graphviz import Digraph\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tikzplotlib\n",
    "# Agent Info -> directories, names, ...\n",
    "from script.experiments_constants import AGENT_EXPERIMENT_INFO\n",
    "from constants import PROJ_ADDR\n",
    "\n",
    "\n",
    "# KPI list and kpi effect list \n",
    "from script.experiments_constants import ENV_KPI_NAME_LIST\n",
    "from script.utils import create_effects_list, create_decisions_list, ensure_directory_exists\n",
    "\n",
    "\n",
    "# Action steering specific loading numerical data and \n",
    "from script.load_data import handle_data\n",
    "from script.symbolic_representation import create_symbolic_state_decision_matrix\n",
    "\n",
    "# Probabiliry Comparison functions\n",
    "from script.probability_comparison import plot_and_save_probability_dist_comparison_heatmaps_with_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils\n",
    "This utility functions will be used as helper to avoid repeating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tikzplotlib_fix_ncols(obj):\n",
    "    \"\"\"\n",
    "    workaround for matplotlib 3.6 renamed legend's _ncol to _ncols, which breaks tikzplotlib\n",
    "    \"\"\"\n",
    "    if hasattr(obj, \"_ncols\"):\n",
    "        obj._ncol = obj._ncols\n",
    "    for child in obj.get_children():\n",
    "        tikzplotlib_fix_ncols(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_dir_for_results(analysis_name, result_dir_addrr=proj_address):\n",
    "    \"\"\"Create the directory path for storing data.\"\"\"\n",
    "    str_helper = f\"A1-NetworkSlicingSchedulingPolicy/results/{analysis_name}\"\n",
    "    path = os.path.join(result_dir_addrr, str_helper)\n",
    "    ensure_directory_exists(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mean KPI values for all users per slice\n",
    "These plots will show the mean KPI values for all users both combined and per slice.\n",
    "The goal is to provide a general overview of the raw numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/1_Numeric_KPI_Per_Slice/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    ############# Load all user scenarios data into one dataframe\n",
    "    agent_numeric_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        kpi_data['user_num'] = number_of_user\n",
    "        agent_numeric_data = pd.concat([agent_numeric_data, kpi_data], axis=0)\n",
    "        del kpi_data, decision_data\n",
    "    \n",
    "    for slice_id in slices:\n",
    "        # Filter data for the current slice\n",
    "        slice_data = agent_numeric_data[agent_numeric_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Group by timestep and calculate mean\n",
    "        mean_kpi_values = slice_data.groupby('timestep')[kpis].mean().reset_index()\n",
    "        \n",
    "        # Remove the first 5 timesteps\n",
    "        mean_kpi_values = mean_kpi_values[mean_kpi_values['timestep'] > 4]\n",
    "        \n",
    "        # Create a new figure for each slice\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 18), sharex=True)\n",
    "        fig.suptitle(f'Average KPI Values Over Time for {agent} - Slice {slice_id}', fontsize=20)\n",
    "        \n",
    "        for i, kpi in enumerate(kpis):\n",
    "            axes[i].plot(mean_kpi_values['timestep'], mean_kpi_values[kpi])\n",
    "            axes[i].set_title(f'{kpi}', fontsize=18)\n",
    "            axes[i].set_ylabel('Average Value', fontsize=16)\n",
    "            axes[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "            axes[i].grid(True)\n",
    "        \n",
    "        axes[-1].set_xlabel('Timestep', fontsize=16)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure as PNG\n",
    "        file_name = f\"{analysis_name}_{agent}_slice_{slice_id}_kpi_over_time\"\n",
    "        png_file_path = os.path.join(plot_path, file_name + \".png\")\n",
    "        plt.savefig(png_file_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        tex_file_path = os.path.join(plot_path, file_name + \".tex\")\n",
    "        tikzplotlib.save(tex_file_path, figure=fig)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "print(\"All plots have been generated and saved as PNG and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Probabilistic View of Symbolic Representation\n",
    "This code blocks will produce the Probability Distributions as one of the probabilistic views of the SymbXRL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob dist for each agent\n",
    "This code will create the plot of probability distributions of the agnet's effects on the environment for each agent.\n",
    "Each plot will show the probability distribution for kpi effects per slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "effects_list = create_effects_list()\n",
    "colors = plt.colormaps['tab10'](np.linspace(0, 1, len(agents)))\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/2_Effect_Probability_Distribution/Effect_Probability_Distribution_per_Agent/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    ############# Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "    \n",
    "    # Create a new figure for each agent\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    fig.suptitle(f'Effect Probability Distribution - {agent}', fontsize=20)\n",
    "    \n",
    "    for i, kpi in enumerate(kpis):\n",
    "        for slice_idx, slice_id in enumerate(slices):\n",
    "            # Filter data for the current slice\n",
    "            slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "            \n",
    "            # Calculate the effect probability\n",
    "            effect_counts = slice_data[kpi].value_counts(normalize=True).reindex(effects_list[kpi], fill_value=0)\n",
    "            \n",
    "            # Plot the probability distribution\n",
    "            axes[i].plot(effect_counts.index, effect_counts.values, marker='o', linestyle='-', \n",
    "                         color=colors[slice_id], label=f'Slice {slice_id}')\n",
    "            axes[i].set_title(f'{kpi}', fontsize=18)\n",
    "            axes[i].set_xlabel('Effect', fontsize=16)\n",
    "            axes[i].set_ylabel('Probability' if i == 0 else '', fontsize=16)\n",
    "            \n",
    "            # Get the current tick locations and labels\n",
    "            locs, labels = axes[i].get_xticks(), axes[i].get_xticklabels()\n",
    "            \n",
    "            # Set both the locations and the labels\n",
    "            axes[i].set_xticks(locs)\n",
    "            axes[i].set_xticklabels(labels, rotation=45, ha='right')\n",
    "            \n",
    "            axes[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "            axes[i].grid(True)\n",
    "            axes[i].legend(fontsize=12)\n",
    "\n",
    "    # Adjust the subplot layout to make room for the rotated labels\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    # Save the figure as PNG\n",
    "    file_name = f\"{analysis_name}_{agent}_effect_probability_distribution\"\n",
    "    png_file_path = os.path.join(plot_path, file_name + \".png\")\n",
    "    plt.savefig(png_file_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_file_path = os.path.join(plot_path, file_name + \".tex\")\n",
    "    tikzplotlib_fix_ncols(fig)\n",
    "    tikzplotlib.save(tex_file_path)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    # break\n",
    "\n",
    "print(\"All effect probability distribution plots have been generated and saved as PNG and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob dist for each Slice\n",
    "This code will create the plot of probability distributions of the agnet's effects on the environment for each slice.\n",
    "In this way we can compare the effect of each agent's effects on each slice of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "effects_list = create_effects_list()\n",
    "colors = plt.colormaps['tab10'](np.linspace(0, 1, len(agents)))\n",
    "\n",
    "for slice_id in slices:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/2_Effect_Probability_Distribution/Effect_Probability_Distribution_per_Slice/Slice_{slice_id}\")\n",
    "    \n",
    "    # Create a new figure for each slice\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=True)\n",
    "    fig.suptitle(f'Effect Probability Distribution - Slice {slice_id}', fontsize=20)\n",
    "    \n",
    "    for i, kpi in enumerate(kpis):\n",
    "        for agent_idx, agent in enumerate(agents):\n",
    "            agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "            \n",
    "            ############# Load all user scenarios data into one dataframe\n",
    "            agent_symbolic_data = pd.DataFrame()\n",
    "            for number_of_user in users:\n",
    "                kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "                symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "                symbolic_effects['user_num'] = number_of_user\n",
    "                agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "                del symbolic_effects, kpi_data, decision_data\n",
    "            \n",
    "            # Filter data for the current slice\n",
    "            slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "            \n",
    "            # Calculate the effect probability\n",
    "            effect_counts = slice_data[kpi].value_counts(normalize=True).reindex(effects_list[kpi], fill_value=0)\n",
    "            \n",
    "            # Plot the probability distribution\n",
    "            axes[i].plot(effect_counts.index, effect_counts.values, marker='o', linestyle='-', \n",
    "                         color=colors[agent_idx], label=agent)\n",
    "        \n",
    "        axes[i].set_title(f'{kpi}', fontsize=18)\n",
    "        axes[i].set_xlabel('Effect', fontsize=16)\n",
    "        axes[i].set_ylabel('Probability' if i == 0 else '', fontsize=16)\n",
    "        \n",
    "        # Get the current tick locations and labels\n",
    "        locs, labels = axes[i].get_xticks(), axes[i].get_xticklabels()\n",
    "        \n",
    "        # Set both the locations and the labels\n",
    "        axes[i].set_xticks(locs)\n",
    "        axes[i].set_xticklabels(labels, rotation=45, ha='right')\n",
    "        \n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].legend(fontsize=12)\n",
    "\n",
    "    # Adjust the subplot layout to make room for the rotated labels\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    \n",
    "    # Save the figure as PNG\n",
    "    file_name = f\"{analysis_name}_slice_{slice_id}_effect_probability_distribution\"\n",
    "    png_file_path = os.path.join(plot_path, file_name + \".png\")\n",
    "    plt.savefig(png_file_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_file_path = os.path.join(plot_path, file_name + \".tex\")\n",
    "    tikzplotlib_fix_ncols(fig)\n",
    "    tikzplotlib.save(tex_file_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "print(\"All effect probability distribution plots have been generated and saved as PNG and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob dist for each KPI\n",
    "This code will create the plot of probability distributions of the agnet's effects on the environment for each KPI.\n",
    "In this way we can compare the effect of each agent's effects on each KPI of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "effects_list = create_effects_list()\n",
    "colors = plt.colormaps['tab10'](np.linspace(0, 1, len(agents)))\n",
    "\n",
    "# Prepare data for all agents\n",
    "all_agent_data = {}\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "    all_agent_data[agent] = agent_symbolic_data\n",
    "\n",
    "for kpi in kpis:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/2_Effect_Probability_Distribution/Effect_Probability_Distribution_per_KPI/{kpi}\")\n",
    "    \n",
    "    # Create a new figure for each KPI\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8), sharey=True)\n",
    "    fig.suptitle(f'Effect Probability Distribution - {kpi}', fontsize=20)\n",
    "    \n",
    "    for i, slice_id in enumerate(slices):\n",
    "        for agent_idx, agent in enumerate(agents):\n",
    "            # Filter data for the current slice\n",
    "            slice_data = all_agent_data[agent][all_agent_data[agent]['slice_id'] == slice_id]\n",
    "            \n",
    "            # Calculate the effect probability\n",
    "            effect_counts = slice_data[kpi].value_counts(normalize=True).reindex(effects_list[kpi], fill_value=0)\n",
    "            \n",
    "            # Plot the probability distribution\n",
    "            axes[i].plot(effect_counts.index, effect_counts.values, marker='o', linestyle='-', \n",
    "                         color=colors[agent_idx], label=agent)\n",
    "        \n",
    "        axes[i].set_title(f'Slice {slice_id}', fontsize=18)\n",
    "        axes[i].set_xlabel('Effect', fontsize=16)\n",
    "        axes[i].set_ylabel('Probability' if i == 0 else '', fontsize=16)\n",
    "        \n",
    "        # Get the current tick locations and labels\n",
    "        locs, labels = axes[i].get_xticks(), axes[i].get_xticklabels()\n",
    "        \n",
    "        # Set both the locations and the labels\n",
    "        axes[i].set_xticks(locs)\n",
    "        axes[i].set_xticklabels(labels, rotation=45, ha='right')\n",
    "        \n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].legend(fontsize=12)\n",
    "\n",
    "    # Adjust the subplot layout to make room for the rotated labels\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    # Save the figure as PNG\n",
    "    file_name = f\"{analysis_name}_{kpi}_effect_probability_distribution\"\n",
    "    png_file_path = os.path.join(plot_path, file_name + \".png\")\n",
    "    plt.savefig(png_file_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_file_path = os.path.join(plot_path, file_name + \".tex\")\n",
    "    tikzplotlib_fix_ncols(fig)\n",
    "    tikzplotlib.save(tex_file_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "print(\"All effect probability distribution plots per KPI have been generated and saved as PNG and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Plotter Util\n",
    "This functino will be used to create the pyvis object that will represent the Graph Analysis of the SymbXRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_from_data_for_presentation(df, column_name):\n",
    "    \"\"\"\n",
    "    This function will receive the data and the column name of the data that you want to plot the graph and \n",
    "    returns the networkX object and the pyvis object and the groups color mapping of the nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    decision_df = []\n",
    "    # Calculate the Cross Matrix\n",
    "    cross_data = pd.crosstab(df[column_name], df[column_name].shift(-1), normalize='index')*100\n",
    "    # Create the directed graph from the transition probabilities\n",
    "    for i, row in cross_data.iterrows():\n",
    "        for j, prob in row.items():\n",
    "            if prob > 0: \n",
    "                decision_df.append({\n",
    "                    'source': i,\n",
    "                    'target': j,\n",
    "                    'weight': prob / 20,\n",
    "                    'size_weight': 1 / prob,\n",
    "                    'title': f'Percentage: {prob}' ,\n",
    "                    'width': prob / 5  # Adjust this value to control the edge width\n",
    "                })\n",
    "\n",
    "    G = nx.from_pandas_edgelist(pd.DataFrame(decision_df), 'source', 'target', edge_attr=['weight', 'title', 'width'], create_using=nx.DiGraph())\n",
    "    \n",
    "    # Add a title attribute to each node containing its name\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['title'] = node\n",
    "    \n",
    "    # Calculate the frequency of each decision in the original DataFrame\n",
    "    decision_counts = df[column_name].value_counts()\n",
    "    \n",
    "    # Apply exponential scaling for node sizes\n",
    "    min_size = 5\n",
    "    scale_factor = 0.55  # Adjust this value to control the exponential growth rate of the sizes\n",
    "    decision_size = {decision: min_size + np.exp(scale_factor * np.log1p(count - 1)) for decision, count in decision_counts.items()}\n",
    "    \n",
    "    # Set the size attribute for each node based on the decision count\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['size'] = decision_size.get(node, min_size)  # Use default size if node not in decision_size\n",
    "\n",
    "    # Add centrality attributes to the nodes --> Not sure what they do\n",
    "    nx.set_node_attributes(G, nx.betweenness_centrality(G, weight='size_weight'), 'betweenness_centrality')\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(G), 'degree_centrality')\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(G, distance='size_weight'), 'closeness_centrality')\n",
    "\n",
    "    # Create the Pyvis network and save it to a file\n",
    "    net = network.Network(\n",
    "        height=\"1500px\", \n",
    "        width=\"100%\", \n",
    "        bgcolor=\"white\",  # Set background color to white\n",
    "        font_color=\"black\",  # Set default font color to black for visibility\n",
    "        directed=True, \n",
    "        notebook=True, \n",
    "        filter_menu=True,  \n",
    "        select_menu=True, \n",
    "        cdn_resources=\"in_line\"\n",
    "    )\n",
    "    net.from_nx(G)\n",
    "    \n",
    "    decision_counts = df[column_name].value_counts(normalize=1)\n",
    "    for node in net.nodes:\n",
    "        node['title'] = f\"node name: {node['title']} \\n prob: {round(100 * decision_counts[node['id']], 1)}%\"\n",
    "        node['color'] = '#1f78b4'  # Set node color to a visible color, e.g., blue\n",
    "        node['font'] = {\n",
    "            'color': 'black',  # Set font color to black\n",
    "            'size': 50  # Increase the font size\n",
    "        }\n",
    "    \n",
    "    for edge in net.edges:\n",
    "        edge['width'] = edge['width']  # Set the edge width from the attribute\n",
    "\n",
    "    # Calculate the graph size\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "\n",
    "    # Create a text element for the graph size information\n",
    "    size_text = f\"Number of Nodes: {num_nodes}<br>Number of Edges: {num_edges}\"\n",
    "\n",
    "    # Add the size information as an HTML element to the Pyvis network\n",
    "    net.add_node(\"size_info\", label=size_text, shape=\"text\", x='-95%', y=0, physics=False)\n",
    "\n",
    "    net.barnes_hut(overlap=1)\n",
    "    net.show_buttons(filter_=['physics'])\n",
    "\n",
    "    return G, net, size_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of graph of decision Per Agent\n",
    "In this part we will produce the Graph Analysis results of SymbXRL for each agnet's mode and traffic profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyvis\n",
    "\n",
    "This code block will use pyvis to create the graph of the decision making process for each agent and visualize it (will create a html file that is better for playing around).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "effects_list = create_effects_list()\n",
    "colors = plt.colormaps['tab10'](np.linspace(0, 1, len(agents)))\n",
    "\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/3_Knowledge_Graphs/Graph_of_Decisions_Per_Agent_Pyvis/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    ############# Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "    \n",
    "    # display(agent_symbolic_data)\n",
    "    # break\n",
    "\n",
    "    for i, slice_id in enumerate(slices):\n",
    "        # Filter the data for the current slice and KPI\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id].copy()\n",
    "        \n",
    "        # Load graph and pyvis object plus group community \n",
    "        G, net, _ = plot_graph_from_data_for_presentation(slice_data, 'combined_decision')\n",
    "        \n",
    "        file_name = f\"Decition_Graph_{agent}_slice-{slice_id}.html\"       \n",
    "        \n",
    "        full_file_path = os.path.join(plot_path, file_name)\n",
    "        net.save_graph(full_file_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph viz\n",
    "\n",
    "This code block will use Graphviz to create the graph of the decision making process for each agent and visualize it (will create a pdf file that is better for looking and using in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_from_data_for_paper(df, column_name, output_path):\n",
    "    cross_data = pd.crosstab(df[column_name], df[column_name].shift(-1), normalize='index')*100\n",
    "    decision_counts = df[column_name].value_counts(normalize=True)\n",
    "    \n",
    "    dot = Digraph(comment='Decision Graph', engine='dot')\n",
    "    dot.attr(rankdir='LR', size='12,8', dpi='300', bgcolor='white')\n",
    "    \n",
    "    # Add nodes\n",
    "    for node, freq in decision_counts.items():\n",
    "        node_size = 1 + 2 * freq  # Moderate size difference\n",
    "        label = node.split(' - ')\n",
    "        label.append(f'prob: {freq:.1%}')\n",
    "        label = '\\n'.join(label)\n",
    "        dot.node(node, label, shape='ellipse', \n",
    "                 width=str(node_size), height=str(node_size),\n",
    "                 style='filled', fillcolor='#E6F3FF', color='#4A6FE3',\n",
    "                 fontname='Arial', fontsize='10')\n",
    "    \n",
    "    # Add edges\n",
    "    for i, row in cross_data.iterrows():\n",
    "        for j, prob in row.items():\n",
    "            if prob > 0:\n",
    "                penwidth = 0.5 + prob/50  # Reduced edge width scaling\n",
    "                dot.edge(i, j, \n",
    "                         label=f'{prob:.1f}%', \n",
    "                         penwidth=str(penwidth),\n",
    "                         color='#4A6FE3',\n",
    "                         fontname='Arial', fontsize='8',\n",
    "                         fontcolor='#4A6FE3')\n",
    "    \n",
    "    # Add legend\n",
    "    dot.attr(label='Node size: state frequency | Edge width: transition probability', \n",
    "             fontname='Arial', fontsize='12', labelloc='t')\n",
    "    \n",
    "    # Save the graph\n",
    "    dot.render(output_path, format='pdf', cleanup=True)\n",
    "    \n",
    "    return dot\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]  # Assuming slices are 0, 1, 2\n",
    "\n",
    "effects_list = create_effects_list()\n",
    "colors = plt.colormaps['tab10'](np.linspace(0, 1, len(agents)))\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/3_Knowledge_Graphs/Graph_of_Decisions_Per_Agent_Graphviz/Final/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    ############# Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "        \n",
    "    for i, slice_id in enumerate(slices):\n",
    "        # Filter the data for the current slice and KPI\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id].copy()\n",
    "        \n",
    "        # Generate and save the graph\n",
    "        file_name = f\"Knowledge_Graph_{agent}_slice-{slice_id}\"\n",
    "        full_file_path = os.path.join(plot_path, file_name)\n",
    "        \n",
    "        dot = plot_graph_from_data_for_paper(slice_data, 'combined_decision', full_file_path)\n",
    "    # break\n",
    "print(\"All decision graphs have been generated and saved as PDF files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Density Maps\n",
    "\n",
    "THis code block will create the Correlation density map of the agetns' decisions and their effects on the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Decision Effect Per Slice for Agent\n",
    "This code will produce hte density maps of the decision and their effect for each agent. the result will be pdfs that contain the density maps for all slices in one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    # Get all unique decisions across all slices\n",
    "    all_decisions = agent_symbolic_data['combined_decision'].unique()\n",
    "    decision_counts = agent_symbolic_data['combined_decision'].value_counts()\n",
    "    sorted_unique_decisions = decision_counts.index.tolist()\n",
    "\n",
    "    # Calculate the height based on the number of decisions\n",
    "    decision_height = 0.3  # Height per decision in inches\n",
    "    min_height = 8  # Minimum height of the plot\n",
    "    calculated_height = max(min_height, len(sorted_unique_decisions) * decision_height)\n",
    "\n",
    "    # Set the figure size with calculated height\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(28, calculated_height), sharey=True)\n",
    "    fig.suptitle(f'Effect Probabilities Heatmaps for Agent {agent}', fontsize=16)\n",
    "\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Concatenate all effects\n",
    "    all_effects = [effect for kpi in kpis for effect in effects_list[kpi]]\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.001:\n",
    "            return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "        return ''\n",
    "\n",
    "    for s, slice_id in enumerate(slices):\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Initialize the matrix for all KPIs and all decisions\n",
    "        div_matrix = np.zeros((len(sorted_unique_decisions), len(all_effects)))\n",
    "\n",
    "        for i, decision in enumerate(sorted_unique_decisions):\n",
    "            decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "            \n",
    "            if not decision_data.empty:\n",
    "                col_index = 0\n",
    "                for kpi in kpis:\n",
    "                    kpi_effects = effects_list[kpi]\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[i, col_index:col_index+len(kpi_effects)] = effect_counts.values\n",
    "                    col_index += len(kpi_effects)\n",
    "\n",
    "        # Normalize the matrix for this slice\n",
    "        div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "        # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "        total_sum = np.sum(div_matrix)\n",
    "        if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "            print(f\"Warning: Sum for slice {slice_id} is {total_sum}, which is not 1.\")\n",
    "\n",
    "        # Create a custom annotation array\n",
    "        annot = np.vectorize(format_value)(div_matrix)\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(div_matrix, ax=axes[s], cmap=cmap, vmin=0, vmax=1, cbar=(s == 2),\n",
    "                    annot=annot, fmt='', annot_kws={'size': 3})\n",
    "        \n",
    "        axes[s].set_title(f'Slice {slice_id}', fontsize=14)\n",
    "        axes[s].set_xlabel('Effects', fontsize=12)\n",
    "        if s == 0:\n",
    "            axes[s].set_ylabel('Decisions', fontsize=12)\n",
    "        \n",
    "        # Adjust x-axis ticks with rotated labels\n",
    "        axes[s].set_xticks(np.arange(len(all_effects)) + 0.5)\n",
    "        axes[s].set_xticklabels(all_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "        \n",
    "        # Adjust y-axis ticks\n",
    "        axes[s].set_yticks(np.arange(len(sorted_unique_decisions)) + 0.5)\n",
    "        axes[s].set_yticklabels(sorted_unique_decisions, rotation=0, fontsize=8)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_All_Slices_in_one/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Decision Effect Per Agent for Slice Seperatly\n",
    "This code will produce hte density maps of the decision and their effect for each slice. the result will be pdfs that contain the density maps for each slice seperatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    # Get all unique decisions across all slices\n",
    "    all_decisions = agent_symbolic_data['combined_decision'].unique()\n",
    "    decision_counts = agent_symbolic_data['combined_decision'].value_counts()\n",
    "    sorted_unique_decisions = decision_counts.index.tolist()\n",
    "\n",
    "    # Calculate the height based on the number of decisions\n",
    "    decision_height = 0.3  # Height per decision in inches\n",
    "    min_height = 8  # Minimum height of the plot\n",
    "    calculated_height = max(min_height, len(sorted_unique_decisions) * decision_height)\n",
    "\n",
    "    # Concatenate all effects\n",
    "    all_effects = [effect for kpi in kpis for effect in effects_list[kpi]]\n",
    "\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    for s, slice_id in enumerate(slices):\n",
    "        # Create a new figure for each slice\n",
    "        fig, ax = plt.subplots(figsize=(20, calculated_height))  # Increased width to accommodate annotations\n",
    "        fig.suptitle(f'Effect Probabilities Heatmap for Agent {agent} - Slice {slice_id}', fontsize=16)\n",
    "\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Initialize the matrix for all KPIs and all decisions\n",
    "        div_matrix = np.zeros((len(sorted_unique_decisions), len(all_effects)))\n",
    "\n",
    "        for i, decision in enumerate(sorted_unique_decisions):\n",
    "            decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "            \n",
    "            if not decision_data.empty:\n",
    "                col_index = 0\n",
    "                for kpi in kpis:\n",
    "                    kpi_effects = effects_list[kpi]\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[i, col_index:col_index+len(kpi_effects)] = effect_counts.values\n",
    "                    col_index += len(kpi_effects)\n",
    "\n",
    "        # Normalize the matrix for this slice\n",
    "        div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "        # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "        total_sum = np.sum(div_matrix)\n",
    "        if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "            print(f\"Warning: Sum for slice {slice_id} is {total_sum}, which is not 1.\")\n",
    "\n",
    "        # Create a custom annotation array\n",
    "        def format_value(val):\n",
    "            if val >= 0.001:\n",
    "                return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "            return ''\n",
    "\n",
    "        annot = np.vectorize(format_value)(div_matrix)\n",
    "\n",
    "        # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "        sns.heatmap(div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=True, \n",
    "                    annot=annot, fmt='', annot_kws={'size': 6})\n",
    "        \n",
    "        ax.set_title(f'Slice {slice_id}', fontsize=14)\n",
    "        ax.set_xlabel('Effects', fontsize=12)\n",
    "        ax.set_ylabel('Decisions', fontsize=12)\n",
    "        \n",
    "        # Adjust x-axis ticks with rotated labels\n",
    "        ax.set_xticks(np.arange(len(all_effects)) + 0.5)\n",
    "        ax.set_xticklabels(all_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "        \n",
    "        # Adjust y-axis ticks\n",
    "        ax.set_yticks(np.arange(len(sorted_unique_decisions)) + 0.5)\n",
    "        ax.set_yticklabels(sorted_unique_decisions, rotation=0, fontsize=8)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure as PDF\n",
    "        slice_output_path = output_path.replace('.pdf', f'_slice_{slice_id}.pdf')\n",
    "        plt.savefig(slice_output_path, dpi=600, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        tex_output_path = slice_output_path.replace('.pdf', '.tex')\n",
    "        tikzplotlib.save(tex_output_path)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Decision Effect Per Agent for Slice Seperatly cleaned\n",
    "\n",
    "This code will produce the same density maps as the previous code but will clean the plot to make it more readable.\n",
    "To make it more readable we will not show the actions that have been made by agent less than 0.01% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    # Concatenate all effects\n",
    "    all_effects = [effect for kpi in kpis for effect in effects_list[kpi]]\n",
    "\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.001:\n",
    "            return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "        return ''\n",
    "\n",
    "    for slice_id in slices:\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Calculate the height based on the number of decisions in this slice\n",
    "        decision_height = 0.3  # Height per decision in inches\n",
    "        min_height = 5  # Minimum height of the plot\n",
    "        calculated_height = max(min_height, len(sorted_slice_decisions) * decision_height)\n",
    "\n",
    "        # Create a new figure for each slice\n",
    "        fig, ax = plt.subplots(figsize=(20, calculated_height))\n",
    "        fig.suptitle(f'Effect Probabilities Heatmap for Agent {agent} - Slice {slice_id}', fontsize=16)\n",
    "\n",
    "        # Initialize the matrix for all KPIs and decisions in this slice\n",
    "        div_matrix = np.zeros((len(sorted_slice_decisions), len(all_effects)))\n",
    "\n",
    "        for i, decision in enumerate(sorted_slice_decisions):\n",
    "            decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "            \n",
    "            if not decision_data.empty:\n",
    "                col_index = 0\n",
    "                for kpi in kpis:\n",
    "                    kpi_effects = effects_list[kpi]\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[i, col_index:col_index+len(kpi_effects)] = effect_counts.values\n",
    "                    col_index += len(kpi_effects)\n",
    "\n",
    "        # Normalize the matrix for this slice\n",
    "        div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "        # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "        total_sum = np.sum(div_matrix)\n",
    "        if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "            print(f\"Warning: Sum for slice {slice_id} is {total_sum}, which is not 1.\")\n",
    "\n",
    "        # Create a custom annotation array\n",
    "        annot = np.vectorize(format_value)(div_matrix)\n",
    "\n",
    "        # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "        sns.heatmap(div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=True, \n",
    "                    annot=annot, fmt='', annot_kws={'size': 6})\n",
    "        \n",
    "        ax.set_title(f'Slice {slice_id}', fontsize=14)\n",
    "        ax.set_xlabel('Effects', fontsize=12)\n",
    "        ax.set_ylabel('Decisions', fontsize=12)\n",
    "        \n",
    "        # Adjust x-axis ticks with rotated labels\n",
    "        ax.set_xticks(np.arange(len(all_effects)) + 0.5)\n",
    "        ax.set_xticklabels(all_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "        \n",
    "        # Adjust y-axis ticks\n",
    "        ax.set_yticks(np.arange(len(sorted_slice_decisions)) + 0.5)\n",
    "        ax.set_yticklabels(sorted_slice_decisions, rotation=0, fontsize=8)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure as PDF\n",
    "        slice_output_path = output_path.replace('.pdf', f'_slice_{slice_id}.pdf')\n",
    "        plt.savefig(slice_output_path, dpi=600, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        tex_output_path = slice_output_path.replace('.pdf', '.tex')\n",
    "        tikzplotlib.save(tex_output_path)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_cleaned_decision/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    # Concatenate all effects\n",
    "    all_effects = [effect for kpi in kpis for effect in effects_list[kpi]]\n",
    "\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.005:  # Changed threshold from 0.001 to 0.01\n",
    "            return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "        return ''\n",
    "\n",
    "    for slice_id in slices:\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Calculate the height based on the number of decisions in this slice\n",
    "        decision_height = 0.3  # Height per decision in inches\n",
    "        min_height = 5  # Minimum height of the plot\n",
    "        calculated_height = max(min_height, len(sorted_slice_decisions) * decision_height)\n",
    "\n",
    "        # Create a new figure for each slice\n",
    "        fig, ax = plt.subplots(figsize=(20, calculated_height))\n",
    "        fig.suptitle(f'Effect Probabilities Heatmap for Agent {agent} - Slice {slice_id}', fontsize=16)\n",
    "\n",
    "        # Initialize the matrix for all KPIs and decisions in this slice\n",
    "        div_matrix = np.zeros((len(sorted_slice_decisions), len(all_effects)))\n",
    "\n",
    "        for i, decision in enumerate(sorted_slice_decisions):\n",
    "            decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "            \n",
    "            if not decision_data.empty:\n",
    "                col_index = 0\n",
    "                for kpi in kpis:\n",
    "                    kpi_effects = effects_list[kpi]\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[i, col_index:col_index+len(kpi_effects)] = effect_counts.values\n",
    "                    col_index += len(kpi_effects)\n",
    "\n",
    "        # Normalize the matrix for this slice\n",
    "        div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "        # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "        total_sum = np.sum(div_matrix)\n",
    "        if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "            print(f\"Warning: Sum for slice {slice_id} is {total_sum}, which is not 1.\")\n",
    "\n",
    "        # Create a custom annotation array\n",
    "        annot = np.vectorize(format_value)(div_matrix)\n",
    "\n",
    "        # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "        sns.heatmap(div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=True, \n",
    "                    annot=annot, fmt='', annot_kws={'size': 6})\n",
    "        \n",
    "        ax.set_title(f'Slice {slice_id}', fontsize=14)\n",
    "        ax.set_xlabel('Effects', fontsize=12)\n",
    "        ax.set_ylabel('Decisions', fontsize=12)\n",
    "        \n",
    "        # Adjust x-axis ticks with rotated labels\n",
    "        ax.set_xticks(np.arange(len(all_effects)) + 0.5)\n",
    "        ax.set_xticklabels(all_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "        \n",
    "        # Adjust y-axis ticks\n",
    "        ax.set_yticks(np.arange(len(sorted_slice_decisions)) + 0.5)\n",
    "        ax.set_yticklabels(sorted_slice_decisions, rotation=0, fontsize=8)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure as PDF\n",
    "        slice_output_path = output_path.replace('.pdf', f'_slice_{slice_id}.pdf')\n",
    "        plt.savefig(slice_output_path, dpi=600, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        tex_output_path = slice_output_path.replace('.pdf', '.tex')\n",
    "        tikzplotlib.save(tex_output_path)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"embb-trf2\", \"urllc-trf1\", \"urllc-trf2\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_cleaned/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Decision Effect Per Agent for Slice Seperatly cleaned - Specific Request\n",
    "\n",
    "This code will produce the specific density maps that we used in the paper. EMBB-TRF1 and URLLC-TRF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    # Concatenate all effects\n",
    "    all_effects = [effect for kpi in kpis for effect in effects_list[kpi]]\n",
    "\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.005:  # Changed threshold from 0.001 to 0.01\n",
    "            return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "        return ''\n",
    "\n",
    "    for slice_id in slices:\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Calculate the height based on the number of decisions in this slice\n",
    "        decision_height = 0.3  # Height per decision in inches\n",
    "        min_height = 5  # Minimum height of the plot\n",
    "        calculated_height = max(min_height, len(sorted_slice_decisions) * decision_height)\n",
    "\n",
    "        # Create a new figure for each slice\n",
    "        fig, ax = plt.subplots(figsize=(20, calculated_height))\n",
    "        fig.suptitle(f'Effect Probabilities Heatmap for Agent {agent} - Slice {slice_id}', fontsize=16)\n",
    "\n",
    "        # Initialize the matrix for all KPIs and decisions in this slice\n",
    "        div_matrix = np.zeros((len(sorted_slice_decisions), len(all_effects)))\n",
    "\n",
    "        for i, decision in enumerate(sorted_slice_decisions):\n",
    "            decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "            \n",
    "            if not decision_data.empty:\n",
    "                col_index = 0\n",
    "                for kpi in kpis:\n",
    "                    kpi_effects = effects_list[kpi]\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[i, col_index:col_index+len(kpi_effects)] = effect_counts.values\n",
    "                    col_index += len(kpi_effects)\n",
    "\n",
    "        # Normalize the matrix for this slice\n",
    "        div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "        # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "        total_sum = np.sum(div_matrix)\n",
    "        if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "            print(f\"Warning: Sum for slice {slice_id} is {total_sum}, which is not 1.\")\n",
    "\n",
    "        # Create a custom annotation array\n",
    "        annot = np.vectorize(format_value)(div_matrix)\n",
    "\n",
    "        # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "        sns.heatmap(div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=True, \n",
    "                    annot=annot, fmt='', annot_kws={'size': 6})\n",
    "        \n",
    "        ax.set_title(f'Slice {slice_id}', fontsize=14)\n",
    "        ax.set_xlabel('Effects', fontsize=12)\n",
    "        ax.set_ylabel('Decisions', fontsize=12)\n",
    "        \n",
    "        # Adjust x-axis ticks with rotated labels\n",
    "        ax.set_xticks(np.arange(len(all_effects)) + 0.5)\n",
    "        ax.set_xticklabels(all_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "        \n",
    "        # Adjust y-axis ticks\n",
    "        ax.set_yticks(np.arange(len(sorted_slice_decisions)) + 0.5)\n",
    "        ax.set_yticklabels(sorted_slice_decisions, rotation=0, fontsize=8)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure as PDF\n",
    "        slice_output_path = output_path.replace('.pdf', f'_slice_{slice_id}.pdf')\n",
    "        plt.savefig(slice_output_path, dpi=600, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        tex_output_path = slice_output_path.replace('.pdf', '.tex')\n",
    "        tikzplotlib.save(tex_output_path)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Scenario\n",
    "\n",
    "These codes will produce the specific scenario that we used in the paper.\n",
    "Each version either apply a visualization affect for better readability or apply a more strict or easier threshold for showing or not showing the cells.\n",
    "\n",
    "All the resutls are the same the difference is just in the way of presenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})  # Reduce default font size for better fit\n",
    "\n",
    "def plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.005:  # Changed threshold from 0.001 to 0.01\n",
    "            return f'{val*100:.1f}%'  # Show as percentage with one decimal place\n",
    "        return ''\n",
    "\n",
    "    for slice_id in slices:\n",
    "        slice_data = agent_symbolic_data[agent_symbolic_data['slice_id'] == slice_id]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than 0.005\n",
    "            row_mask = np.any(div_matrix > 0.005, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix to ensure the sum is 1\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            # Save the filtered data for plotting\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "\n",
    "        # Determine the maximum number of rows to set the height of the plot dynamically\n",
    "        max_rows = max(len(filtered_decisions) for filtered_decisions in filtered_decisions_list)\n",
    "        plot_height = max(5, max_rows * 0.2)  # Set minimum height to 5 inches and 0.5 inches per row\n",
    "\n",
    "        # Create a new figure for each slice with a 1x3 layout for the KPIs\n",
    "        fig = plt.figure(figsize=(20, plot_height))\n",
    "        gs = fig.add_gridspec(nrows=1, ncols=len(kpis) + 1, width_ratios=[1]*len(kpis) + [0.05])\n",
    "        fig.suptitle(f'Effect Probabilities Heatmap for Agent {agent} - Slice {slice_id}', fontsize=16)\n",
    "\n",
    "        axs = [fig.add_subplot(gs[0, i]) for i in range(len(kpis))]\n",
    "\n",
    "        for i, (ax, kpi, filtered_div_matrix, filtered_decisions) in enumerate(zip(axs, kpis, filtered_div_matrices, filtered_decisions_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for slice {slice_id}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(filtered_div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6})\n",
    "            \n",
    "            ax.set_title(f'{kpi}', fontsize=14)\n",
    "            ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Decisions', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(kpi_effects)) + 0.5)\n",
    "            ax.set_xticklabels(kpi_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Add a single colorbar to the right of all subplots\n",
    "        cbar_ax = fig.add_subplot(gs[0, -1])\n",
    "        fig.colorbar(axs[0].collections[0], cbar_ax, orientation='vertical')\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Save the figure as PDF\n",
    "        slice_output_path = output_path.replace('.pdf', f'_slice_{slice_id}.pdf')\n",
    "        plt.savefig(slice_output_path, dpi=600, bbox_inches='tight')\n",
    "        \n",
    "        # Save the figure as LaTeX using tikzplotlib\n",
    "        # tex_output_path = slice_output_path.replace('.pdf', '.tex')\n",
    "        # tikzplotlib_fix_ncols\n",
    "        # tikzplotlib.save(tex_output_path)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "users = range(3, 7)\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0, 1, 2]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "for agent in agents:\n",
    "    plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/{agent}\")\n",
    "    \n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    \n",
    "    # Load all user scenarios data into one dataframe\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in users:\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    # Generate and save the heatmap\n",
    "    output_file = os.path.join(plot_path, f\"{agent}_heatmaps.pdf\")\n",
    "    plot_heatmaps_for_paper(agent_symbolic_data, agent, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"All heatmaps have been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed unsued rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.01:\n",
    "            return f'{val*100:.1f}%'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than 0.008\n",
    "            row_mask = np.any(div_matrix > 0.008, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix to ensure the sum is 1\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            # Save the filtered data for plotting\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions) in enumerate(zip(axs[row], kpis, filtered_div_matrices, filtered_decisions_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for slice {slice_id}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(filtered_div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6})\n",
    "            \n",
    "            ax.set_title(f'{agent_name} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel('Decisions', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(kpi_effects)) + 0.5)\n",
    "            ax.set_xticklabels(kpi_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)  # Reduce these values to decrease space between subplots\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# Main execution\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Define the threshold values for each agent\n",
    "    agent_thresholds = {\n",
    "        \"embb-trf1\": 0.01,  # 1 percent\n",
    "        \"urllc-trf1\": 0.02  # 2 percent\n",
    "    }\n",
    "\n",
    "    def format_value(val, threshold):\n",
    "        if np.isnan(val):\n",
    "            return ''\n",
    "        if val >= threshold:\n",
    "            return f'{round(val * 100):d}'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a mask for significant decisions across all KPIs\n",
    "        significant_decisions_mask = np.zeros(len(sorted_slice_decisions), dtype=bool)\n",
    "\n",
    "        # First pass: determine significant decisions across all KPIs\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "            significant_decisions_mask |= np.any(div_matrix > threshold, axis=1)\n",
    "\n",
    "        # Filter decisions using the unified mask\n",
    "        filtered_decisions = np.array(sorted_slice_decisions)[significant_decisions_mask]\n",
    "\n",
    "        # Second pass: create filtered matrices for each KPI\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "            filtered_div_matrix = div_matrix[significant_decisions_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append([filtered_decisions] * len(kpis))\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        agent_name = agents[row]\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Mask values lower than the threshold\n",
    "            display_matrix = np.where(filtered_div_matrix >= threshold, filtered_div_matrix, np.nan)\n",
    "\n",
    "            # Re-normalize the display values to ensure the sum is 1\n",
    "            display_matrix = display_matrix / np.nansum(display_matrix)\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(display_matrix, threshold)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(display_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6}, mask=np.isnan(display_matrix))\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'Decisions ({agents[row]})', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# The rest of your code remains the same\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3.2_masked_No_DN_Filter_White/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    def format_value(val):\n",
    "        if val >= 0.01:\n",
    "            return f'{val*100:.1f}%'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than 0.008\n",
    "            row_mask = np.any(div_matrix > 0.008, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Append the filtered matrices and decisions to the lists\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append(filtered_decisions_list)\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices and decisions based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(filtered_div_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6})\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel('Decisions', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)  # Reduce these values to decrease space between subplots\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3_masked/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3.2 masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Define the threshold values for each agent\n",
    "    agent_thresholds = {\n",
    "        \"embb-trf1\": 0.01,  # 1 percent\n",
    "        \"urllc-trf1\": 0.02  # 2 percent\n",
    "    }\n",
    "\n",
    "    def format_value(val, threshold):\n",
    "        if val >= threshold:\n",
    "            return f'{round(val * 100):d}'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than the threshold\n",
    "            row_mask = np.any(div_matrix > threshold, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix to ensure the sum is 1\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            # Append the filtered matrices and decisions to the lists\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append(filtered_decisions_list)\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices and decisions based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        agent_name = agents[row]\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix, threshold)\n",
    "\n",
    "            # Re-normalize the display values to ensure the sum is 1\n",
    "            display_matrix = np.where(filtered_div_matrix >= threshold, filtered_div_matrix, 0)\n",
    "            display_matrix = display_matrix / np.sum(display_matrix)\n",
    "\n",
    "            annot = np.vectorize(format_value)(display_matrix, threshold)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(display_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6})\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'Decisions ({agents[row]})', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)  # Reduce these values to decrease space between subplots\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3.2_masked_No_DN/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Witout Decimal Poitns by filtering out empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Define the threshold values for each agent\n",
    "    agent_thresholds = {\n",
    "        \"embb-trf1\": 0.01,  # 1 percent\n",
    "        \"urllc-trf1\": 0.02  # 2 percent\n",
    "    }\n",
    "\n",
    "    def format_value(val, threshold):\n",
    "        if np.isnan(val):\n",
    "            return ''\n",
    "        if val >= threshold:\n",
    "            return f'{round(val * 100):d}'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a mask for significant decisions across all KPIs\n",
    "        significant_decisions_mask = np.zeros(len(sorted_slice_decisions), dtype=bool)\n",
    "\n",
    "        # First pass: determine significant decisions across all KPIs\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "            significant_decisions_mask |= np.any(div_matrix > threshold, axis=1)\n",
    "\n",
    "        # Filter decisions using the unified mask\n",
    "        filtered_decisions = np.array(sorted_slice_decisions)[significant_decisions_mask]\n",
    "\n",
    "        # Second pass: create filtered matrices for each KPI\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "            filtered_div_matrix = div_matrix[significant_decisions_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append([filtered_decisions] * len(kpis))\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        agent_name = agents[row]\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Mask values lower than the threshold\n",
    "            display_matrix = np.where(filtered_div_matrix >= threshold, filtered_div_matrix, np.nan)\n",
    "\n",
    "            # Re-normalize the display values to ensure the sum is 1\n",
    "            display_matrix = display_matrix / np.nansum(display_matrix)\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(display_matrix, threshold)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(display_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6}, mask=np.isnan(display_matrix))\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'Decisions ({agents[row]})', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# The rest of your code remains the same\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3.2_masked_No_DN_Filter_White/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With one Decimal Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Define the threshold values for each agent\n",
    "    agent_thresholds = {\n",
    "        \"embb-trf1\": 0.005,  # 1 percent\n",
    "        \"urllc-trf1\": 0.02  # 2 percent\n",
    "    }\n",
    "\n",
    "    def format_value(val, threshold):\n",
    "        if val >= threshold:\n",
    "            return f'{val * 100:.1f}'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than the threshold\n",
    "            row_mask = np.any(div_matrix > threshold, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix to ensure the sum is 1\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            # Append the filtered matrices and decisions to the lists\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append(filtered_decisions_list)\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices and decisions based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        agent_name = agents[row]\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix, threshold)\n",
    "\n",
    "            # Re-normalize the display values to ensure the sum is 1\n",
    "            display_matrix = np.where(filtered_div_matrix >= threshold, filtered_div_matrix, 0)\n",
    "            display_matrix = display_matrix / np.sum(display_matrix)\n",
    "\n",
    "            annot = np.vectorize(format_value)(display_matrix, threshold)\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(display_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6})\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'Decisions ({agents[row]})', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)  # Reduce these values to decrease space between subplots\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3.2_masked_With_DN/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With decimal points by filtering out empty cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_path):\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Define the threshold values for each agent\n",
    "    agent_thresholds = {\n",
    "        \"embb-trf1\": 0.005,  # 1 percent\n",
    "        \"urllc-trf1\": 0.02  # 2 percent\n",
    "    }\n",
    "\n",
    "    def format_value(val, threshold):\n",
    "        if val >= threshold:\n",
    "            return f'{val * 100:.1f}'\n",
    "        return ''\n",
    "\n",
    "    # Initialize a 2x3 layout for the combined plot (2 agents x 3 KPIs)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "    fig.suptitle('Combined Heatmaps for Agents and Slices', fontsize=16)\n",
    "\n",
    "    # Initialize lists to store data for both rows\n",
    "    row_filtered_decisions_list = []\n",
    "    row_filtered_div_matrices_list = []\n",
    "    row_filtered_effects_list = []\n",
    "\n",
    "    for row, (agent, slice_id) in enumerate(agent_data_dict.items()):\n",
    "        slice_data = slice_id['data']\n",
    "        agent_name = slice_id['agent']\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        \n",
    "        # Get unique decisions for this slice\n",
    "        slice_decisions = slice_data['combined_decision'].unique()\n",
    "        decision_counts = slice_data['combined_decision'].value_counts()\n",
    "        sorted_slice_decisions = decision_counts.index.tolist()\n",
    "\n",
    "        # Initialize a list to store filtered decisions and their corresponding matrices for each KPI\n",
    "        filtered_decisions_list = []\n",
    "        filtered_div_matrices = []\n",
    "        filtered_effects_list = []\n",
    "\n",
    "        for kpi in kpis:\n",
    "            kpi_effects = effects_list[kpi]\n",
    "            # Initialize the matrix for the current KPI and decisions in this slice\n",
    "            div_matrix = np.zeros((len(sorted_slice_decisions), len(kpi_effects)))\n",
    "\n",
    "            for j, decision in enumerate(sorted_slice_decisions):\n",
    "                decision_data = slice_data[slice_data['combined_decision'] == decision]\n",
    "                \n",
    "                if not decision_data.empty:\n",
    "                    effect_counts = decision_data[kpi].value_counts().reindex(kpi_effects, fill_value=0)\n",
    "                    div_matrix[j] = effect_counts.values\n",
    "\n",
    "            # Normalize the matrix for this slice\n",
    "            div_matrix = div_matrix / np.sum(div_matrix)\n",
    "\n",
    "            # Filter out rows where no cell has a value greater than the threshold\n",
    "            row_mask = np.any(div_matrix > threshold, axis=1)\n",
    "            filtered_div_matrix = div_matrix[row_mask]\n",
    "            filtered_decisions = np.array(sorted_slice_decisions)[row_mask]\n",
    "\n",
    "            # Re-normalize the filtered matrix to ensure the sum is 1\n",
    "            filtered_div_matrix = filtered_div_matrix / np.sum(filtered_div_matrix)\n",
    "\n",
    "            # Append the filtered matrices and decisions to the lists\n",
    "            filtered_decisions_list.append(filtered_decisions)\n",
    "            filtered_div_matrices.append(filtered_div_matrix)\n",
    "            filtered_effects_list.append(kpi_effects)\n",
    "\n",
    "        # Store the filtered data for this row\n",
    "        row_filtered_decisions_list.append(filtered_decisions_list)\n",
    "        row_filtered_div_matrices_list.append(filtered_div_matrices)\n",
    "        row_filtered_effects_list.append(filtered_effects_list)\n",
    "\n",
    "    # Determine columns to keep across both rows for each KPI\n",
    "    final_filtered_effects_list = []\n",
    "    for kpi_idx in range(len(kpis)):\n",
    "        combined_mask = np.zeros(len(effects_list[kpis[kpi_idx]]), dtype=bool)\n",
    "        for row_filtered_div_matrices in row_filtered_div_matrices_list:\n",
    "            combined_mask |= np.any(row_filtered_div_matrices[kpi_idx] > 0.008, axis=0)\n",
    "        final_filtered_effects = np.array(effects_list[kpis[kpi_idx]])[combined_mask]\n",
    "        final_filtered_effects_list.append(final_filtered_effects)\n",
    "\n",
    "        # Re-filter the matrices and decisions based on the combined mask\n",
    "        for row in range(2):\n",
    "            row_filtered_div_matrices_list[row][kpi_idx] = row_filtered_div_matrices_list[row][kpi_idx][:, combined_mask]\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    for row in range(2):\n",
    "        agent_name = agents[row]\n",
    "        threshold = agent_thresholds[agent_name]\n",
    "        for col, (ax, kpi, filtered_div_matrix, filtered_decisions, final_filtered_effects) in enumerate(zip(\n",
    "                axs[row], kpis, row_filtered_div_matrices_list[row], row_filtered_decisions_list[row], final_filtered_effects_list)):\n",
    "            # Verify that the sum is 1 (or very close to 1 due to floating-point precision)\n",
    "            total_sum = np.sum(filtered_div_matrix)\n",
    "            if not np.isclose(total_sum, 1.0, atol=1e-6):\n",
    "                print(f\"Warning: Sum for agent {agents[row]}, KPI {kpi} is {total_sum}, which is not 1.\")\n",
    "\n",
    "            # Create a custom annotation array\n",
    "            annot = np.vectorize(format_value)(filtered_div_matrix, threshold)\n",
    "\n",
    "            # Re-normalize the display values to ensure the sum is 1\n",
    "            display_matrix = np.where(filtered_div_matrix >= threshold, filtered_div_matrix, 0)\n",
    "            display_matrix = display_matrix / np.sum(display_matrix)\n",
    "\n",
    "            # Update annotation array after re-normalization\n",
    "            annot = np.vectorize(format_value)(display_matrix, threshold)\n",
    "\n",
    "            # Create a mask to hide values below the threshold\n",
    "            mask = display_matrix == 0\n",
    "\n",
    "            # Plot heatmap with fixed scale from 0 to 1 and display formatted values\n",
    "            sns.heatmap(display_matrix, ax=ax, cmap=cmap, vmin=0, vmax=1, cbar=False, \n",
    "                        annot=annot, fmt='', annot_kws={'size': 6}, mask=mask)\n",
    "            \n",
    "            ax.set_title(f'{agents[row]} - {kpi}', fontsize=14)\n",
    "            if row == 1:\n",
    "                ax.set_xlabel('Effects', fontsize=12)\n",
    "\n",
    "            # Only set y-axis labels for the first subplot in each row\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'Decisions ({agents[row]})', fontsize=12)\n",
    "                ax.set_yticks(np.arange(len(filtered_decisions)) + 0.5)\n",
    "                ax.set_yticklabels(filtered_decisions, rotation=0, fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Adjust x-axis ticks with rotated labels\n",
    "            ax.set_xticks(np.arange(len(final_filtered_effects)) + 0.5)\n",
    "            ax.set_xticklabels(final_filtered_effects, rotation=45, ha='right', va='top', fontsize=6)\n",
    "\n",
    "        # Remove x-axis labels for the first row\n",
    "        if row == 0:\n",
    "            for col in range(3):\n",
    "                axs[row, col].set_xticklabels([])\n",
    "\n",
    "    # Add a single color bar to the right of the plot\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.001, hspace=0.01)  # Reduce these values to decrease space between subplots\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    \n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    # Save the figure as LaTeX using tikzplotlib\n",
    "    tex_output_path = output_path.replace('.pdf', '.tex')\n",
    "    tikzplotlib.save(tex_output_path)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analysis_name = \"Plots_for_Paper\"\n",
    "agents = [\"embb-trf1\", \"urllc-trf1\"]\n",
    "kpis = ['tx_brate', 'tx_pckts', 'dl_buffer']\n",
    "slices = [0]\n",
    "effects_list = create_effects_list()\n",
    "\n",
    "agent_data_dict = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_info = AGENT_EXPERIMENT_INFO[agent]\n",
    "    agent_symbolic_data = pd.DataFrame()\n",
    "    for number_of_user in range(3, 7):\n",
    "        kpi_data, decision_data = handle_data(agent_info, number_of_user)\n",
    "        symbolic_effects, _ = create_symbolic_state_decision_matrix(kpi_data, decision_data, agent_info, number_of_user)\n",
    "        symbolic_effects['user_num'] = number_of_user\n",
    "        symbolic_effects['combined_decision'] = symbolic_effects.apply(lambda row: f\"{row['prb_decision']} - {row['sched_decision']}\", axis=1)\n",
    "        agent_symbolic_data = pd.concat([agent_symbolic_data, symbolic_effects], axis=0)\n",
    "        del symbolic_effects, kpi_data, decision_data\n",
    "\n",
    "    agent_data_dict[agent] = {'data': agent_symbolic_data[agent_symbolic_data['slice_id'] == 0], 'agent': agent}\n",
    "\n",
    "# Generate and save the heatmap\n",
    "plot_path = create_plot_dir_for_results(analysis_name + f\"/4_Heatmaps/Heatmap_of_Decision_Effect_per_slice_specific_scenario/V3.2_masked_With_DN_Filter_white/\")\n",
    "output_file = os.path.join(plot_path, f\"combined_heatmaps.pdf\")\n",
    "\n",
    "plot_combined_heatmaps_for_paper(agent_data_dict, agents, effects_list, kpis, slices, output_file)\n",
    "\n",
    "print(\"Combined heatmap has been generated and saved as PDF and LaTeX files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbxrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
